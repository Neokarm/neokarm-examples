# Service Exposure

This guide will explain how to expose kubernetes services externally, to be consumed outside of the kubernetes cluster, with high availability.

- [Load Balancer Controller Integration](#load-balancer-controller-integration)
- [Manual Setup](#manual-setup)

## [Load Balancer Controller](<(https://github.com/kubernetes-sigs/aws-load-balancer-controller)>) Integration (zCompute v22.02+ only)

zCompute's AWS API can be leveraged to be used with AWS Load Balancer Controller to provision NLBs and ALBs that will operate as a Kubernetes `Ingress` or as an external LoadBalancer `Service`.

## Caveates

- **Target Types** - since the AWS VPC CNI isn't supported on zCompute, only the `instance` target type (the default) is supported.
- **Subnet Discovery** - tag values must be explicitly set due to a limitation in zCompute. For instance, to mark a private subnet use the tag `kubernetes.io/role/internal-elb=1`, empty tag value (`kubernetes.io/role/internal-elb=`) won't work.
- **Authentication** - zCompute's LB service does not support authentication actions, so the relevant annotations should not be used.
- **Protocols** - Currently the only supported listener protocols are `TCP`, `HTTP` and `HTTPS`, for health check protocols the only supported protocols are `TCP` and `HTTP`.

## Usage

### 1. Allow cluster to pull images from AWS ECR

> By default the controller image is pulled from 602401143452.dkr.ecr.us-west-2.amazonaws.com.
> If you decide to pull from another registry the attached script need to be modified.
> Run the provided `ecr-access` script, `docker` and `aws` CLI are required.
> What the script does:

- Obtains a login password from ECR using AWS CLI.
- Logins with the obtained password to the image repository using docker.
- Creates a Kubernetes secret (`aws-ecr-pull-secret`) in the `kube-system` namespace, with the content of the generated docker config (containing you AWS auth creds).

### 2. Create the ca-certificate ConfigMap:

> If you used the provided terraform files to install the Kubernetes cluster, use the `ca-certificates.crt` that was generated by it.

```sh
kubectl -n kube-system create configmap --from-file=ca-certificates.crt zcompute-ca-certificates-bundle
```

### 3. Configure the helm chart:

Copy the provided `values.yaml.template` to `values.yaml`, and replace `${zcompute-hostname}` with the appropiate zCompute cluster DNS name.
Additional values can be provided and changed in accordance with the chart docs.

### 4. Install the helm chart:

```sh
helm repo add eks https://aws.github.io/eks-charts
helm repo update
helm install aws-load-balancer-controller eks/aws-load-balancer-controller -n kube-system -f values.yaml
```

### 5. Resources

The controller is ready at this point and resources can be created.

- For kuberenetes `Service` resource make sure the `Service` type is `LoadBalancer` and that the resource has the following annotations:
  ```yaml
  service.beta.kubernetes.io/aws-load-balancer-type: external
  service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: instance
  alb.ingress.kubernetes.io/scheme: internal / internet-facing
  ```
- For kubernetes `Ingress` resource make sure it's annotated by the ingress class the controller is configured to watch (by default `alb`), and to specify a scheme:
  ```yaml
  kubernetes.io/ingress.class: alb
  alb.ingress.kubernetes.io/scheme: internal / internet-facing
  ```

## Manual Setup

Two optional approches:

- **Load Balancing `NodePort` Services:**

  In this method you create `NodePort` services for deploymnets you wish to expose, and use a load balancer to route traffix to this port for all kubernetes worker nodes.

  Create a target group with all kubernetes worker nodes as targets, with the target port being, the port specified by the `NodePort` service specification. Forward traffic to this target group, in one of the following ways:

  - Dedicate a Load Balancer to a single service - 1-to-1 loadbalancer-service relation.
  - Dedicate a Listener to a single service - the load balancer will traffic to multiple services according to the listener port.
  - Rule-based traffic routing - a single load balancer and listener is used, traffic is routed according to load balancer rules such as HTTP path, hostname, headers, etc...

  This method requires a lot of manual integration but offers the most flexibility in terms of traffic routing logic.

- **Web Server Ingress:**

  In this method you expose services using a web-server-based ingress such as [NGINX Ingress Controller](https://kubernetes.github.io/ingress-nginx/) (which also comes pre-installed on the RKE2 cluster installed by the provided terraform) or [HAProxy Ingress](https://haproxy-ingress.github.io/). Exposing the services is done in a kubernetes-native way, according to the the specific ingress provider.

  To provide load balancing and high availablity to this ingress, you need to create a load balancer to the ingress service, as described in the previous bullet.

  This method can be viewed as a one-time setup method, where you just configure loadbalancing the ingress service `NodePort`, and then exposing other services in a kubernetes-native way using the ingress controller. The downsides of this method is that the traffic routing is limited by the ingress controller capabilities.
